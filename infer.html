<!DOCTYPE html>
<meta charset="utf-8">
<!-- https://github.com/epicure/llama2.js -->
<!-- https://github.com/karpathy/llama2.c#notable-forks -->
<title>llama2.js</title>
<style>
    body {
        padding: 1em;
    }
    label, button {
        margin: 0.5em;
    }
    input {
        width: 5em;
    }
    textarea {
        padding: 1em;
    }
</style>
<body>
    <div>
        <div>
            <textarea id="prompt" type="text" value="" cols="80" rows="1" placeholder="One day"></textarea>
        </div>
        <select id="model">
            <option value="stories15m">stories15m</option>
            <option value="stories42m">stories42m</option>
            <option value="stories110m">stories110m</option>
        </select>

        <label>top-p</label><input id="top-p" type="number" value="1.0" step="0.1">
        <label>temperature</label><input id="temperature" type="number" value="0.9" step="0.1">
        <label>steps</label><input id="steps" type="number" value="100">
        <button id="run">run</button>
    </div>
    <textarea id="output" rows="20" cols="80"></textarea>
    <p><span>achieved tok/s: </span><span id="toks"></span></p>
</body>
<script>
    // About this code
    // This is a JavaScript port of llama2.c, a tiny neural net language model

    let config, vocab, vocab_scores, weights, tokenizer_config, run_state;
    let is_generating = false;

    // ----------------------------------------------------------------------------
    // initialization: read from checkpoint

    async function load_model(path) {
        const response = await fetch(path);
        const arrayBuffer = await response.arrayBuffer();

        const SIZE_OF_DTYPE = 4;
        const header_length = 256;

        let offset = 0;

        let header = new Int32Array(arrayBuffer.slice(0, header_length));

        let magic_number_0 = header[0];
        let magic_number_1 = header[1];

        if(magic_number_0 !== 0x42443453 || magic_number_1 !== 0x55524c4d) {
            console.error("Error: Corrupted or wrong model file!");
            return false;
        }

        let major_version = header[2];
        let minor_version = header[3];

        console.info(`Model version: ${major_version}.${minor_version}`);

        let config = {
            block_size: 0,
            vocab_size: 0,
            n_layer: 0,
            n_embd: 0,
            n_head: 0,
            n_kv_head: 0,
            n_hidden: 0,
            is_shared_classifier: 0
        };

        let cfg_keys = Object.keys(config);
        header.slice(4, 4 + cfg_keys.length).forEach((v, i) => {
            config[cfg_keys[i]] = v;
        });

        offset += header_length;

        const cfg = config;

        const is_shared_weights = cfg.is_shared_classifier > 0 ? 1 : 0;

        // initialization: read from checkpoint
        const head_dim = cfg.n_embd / cfg.n_head;

        // token embedding table
        let token_embedding_table = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.vocab_size * cfg.n_embd));
        // weights for rmsnorms
        let rms_att_weight = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.n_layer * cfg.n_embd));
        // weights for matmuls
        let wq = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.n_layer * cfg.n_embd * cfg.n_embd));
        let wk = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.n_layer * cfg.n_embd * cfg.n_kv_head * head_dim));
        let wv = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.n_layer * cfg.n_embd * cfg.n_kv_head * head_dim));
        let wo = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.n_layer * cfg.n_embd * cfg.n_embd));
        // weights for rmsnorms
        let rms_ffn_weight = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.n_layer * cfg.n_embd));
        // weights for ffn
        let w1 = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.n_layer * cfg.n_embd * cfg.n_hidden));
        let w2 = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.n_layer * cfg.n_embd * cfg.n_hidden));
        let w3 = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.n_layer * cfg.n_embd * cfg.n_hidden));
        // final rmsnorm
        let rms_final_weight = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.n_embd));
        // freq_cis for RoPE relatively positional embeddings
        let freq_cis_real = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.block_size * head_dim / 2));
        let freq_cis_imag = new Float32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE * cfg.block_size * head_dim / 2));
        // (optional) classifier weights for the logits, on the last layer
        let wcls = null;

        weights = {
            token_embedding_table: token_embedding_table,
            rms_att_weight: rms_att_weight,
            wq: wq,
            wk: wk,
            wv: wv,
            wo: wo,
            rms_ffn_weight: rms_ffn_weight,
            w1: w1,
            w2: w2,
            w3: w3,
            rms_final_weight: rms_final_weight,
            freq_cis_real: freq_cis_real,
            freq_cis_imag: freq_cis_imag,
            wcls: wcls
        };
        weights.wcls = is_shared_weights ? weights.token_embedding_table : offset;

        tk_length_field = new Uint32Array(arrayBuffer.slice(offset, offset += SIZE_OF_DTYPE));
        tk_length = tk_length_field[0];
        tokenizer_config_json_base64 = new Uint8Array(arrayBuffer.slice(offset, offset += tk_length));
        const text_decoder = new TextDecoder("utf-8");
        tokenizer_config_json_base64_str = text_decoder.decode(tokenizer_config_json_base64);
        tokenizer_config_json_str = window.atob(tokenizer_config_json_base64_str);
        tokenizer_config = JSON.parse(tokenizer_config_json_str);
        console.log(tokenizer_config);

        run_state = {
            // current wave of activations
            x: new Float32Array(cfg.n_embd), // activation at current time stamp (dim,)
            xb: new Float32Array(cfg.n_embd), // same, but inside a residual branch (dim,)
            xb2: new Float32Array(cfg.n_embd), // an additional buffer just for convenience (dim,)
            hb: new Float32Array(cfg.n_hidden), // buffer for hidden dimension in the ffn (hidden_dim,)
            hb2: new Float32Array(cfg.n_hidden), // buffer for hidden dimension in the ffn (hidden_dim,)
            q: new Float32Array(cfg.n_embd), // query (dim,)
            k: new Float32Array(cfg.n_embd), // key (dim,)
            v: new Float32Array(cfg.n_embd), // value (dim,)
            att: new Float32Array(cfg.n_head * cfg.block_size), // buffer for scores/attention values (n_heads, seq_len)
            logits: new Float32Array(cfg.vocab_size), // output logits
            // kv cache
            key_cache: new Float32Array(cfg.n_layer * cfg.block_size * cfg.n_embd),   // (layer, seq_len, dim)
            value_cache: new Float32Array(cfg.n_layer * cfg.block_size * cfg.n_embd), // (layer, seq_len, dim)
        };
    }


    // ----------------------------------------------------------------------------
    // neural net blocks

    function accum(a, b, size) {
        for (let i = 0; i < size; i++) {
            a[i] += b[i];
        }
    }

    function rmsnorm(o, x, weight, size) {
        // calculate sum of squares
        let ss = 0.0;
        for (let j = 0; j < size; j++) {
            ss += x[j] * x[j];
        }
        ss /= size;
        ss += 1e-5;
        ss = 1.0 / Math.sqrt(ss);
        // normalize and scale
        for (let j = 0; j < size; j++) {
            o[j] = weight[j] * (ss * x[j]);
        }
    }

    function softmax(x, size) {
        // find max value (for numerical stability)
        let max_val = x[0];
        for (let i = 1; i < size; i++) {
            if (x[i] > max_val) {
                max_val = x[i];
            }
        }
        // exp and sum
        let sum = 0.0;
        for (let i = 0; i < size; i++) {
            x[i] = Math.exp(x[i] - max_val);
            sum += x[i];
        }
        // normalize
        for (let i = 0; i < size; i++) {
            x[i] /= sum;
        }
    }

    function matmul(xout, x, w, n, d) {
        // W (d,n) @ x (n,) -> xout (d,)
        for (let i = 0; i < d; i++) {
            let val = 0.0;
            for (let j = 0; j < n; j++) {
                val += w[i * n + j] * x[j];
            }
            xout[i] = val;
        }
    }

    function transformer(token, pos, cfg, s, w) {
        // cfg = config, s = run_state, w = weights
        // a few convenience variables
        let x = s.x;
        const dim = cfg.n_embd;
        const hidden_dim = cfg.n_hidden;
        const head_dim = dim / cfg.n_head;

        // copy the token embedding into x
        x.set(w.token_embedding_table.subarray(token * dim, (token + 1) * dim));
        
        // pluck out the "pos" row of freq_cis_real and freq_cis_imag
        const freq_cis_real_row = w.freq_cis_real.subarray(pos * head_dim / 2, (pos + 1) * head_dim / 2);
        const freq_cis_imag_row = w.freq_cis_imag.subarray(pos * head_dim / 2, (pos + 1) * head_dim / 2);
        
        // forward all the layers
        for(let l = 0; l < cfg.n_layer; l++) {
            // attention rmsnorm
            rmsnorm(s.xb, x, w.rms_att_weight.subarray(l * dim, (l + 1) * dim), dim);

            // qkv matmuls for this position
            matmul(s.q, s.xb, w.wq.subarray(l * dim * dim, (l + 1) * dim * dim), dim, dim);
            matmul(s.k, s.xb, w.wk.subarray(l * dim * dim, (l + 1) * dim * dim), dim, dim);
            matmul(s.v, s.xb, w.wv.subarray(l * dim * dim, (l + 1) * dim * dim), dim, dim);

            // apply RoPE rotation to the q and k vectors for each head
            for (let h = 0; h < cfg.n_head; h++) {
                // get the q and k vectors for this head
                const q = s.q.subarray(h * head_dim, (h + 1) * head_dim);
                const k = s.k.subarray(h * head_dim, (h + 1) * head_dim);
                // rotate q and k by the freq_cis_real and freq_cis_imag
                for (let i = 0; i < head_dim; i += 2) {
                    const q0 = q[i];
                    const q1 = q[i + 1];
                    const k0 = k[i];
                    const k1 = k[i + 1];
                    const fcr = freq_cis_real_row[i / 2];
                    const fci = freq_cis_imag_row[i / 2];
                    q[i] = q0 * fcr - q1 * fci;
                    q[i + 1] = q0 * fci + q1 * fcr;
                    k[i] = k0 * fcr - k1 * fci;
                    k[i + 1] = k0 * fci + k1 * fcr;
                }
            }

            // save key,value at this time step (pos) to our kv cache
            const loff = l * cfg.block_size * dim; // kv cache layer offset for convenience
            const key_cache_row = s.key_cache.subarray(loff + pos * dim, loff + (pos + 1) * dim);
            const value_cache_row = s.value_cache.subarray(loff + pos * dim, loff + (pos + 1) * dim);
            key_cache_row.set(s.k);
            value_cache_row.set(s.v);

            // multihead attention. iterate over all heads
            for (let h = 0; h < cfg.n_head; h++) {
                // get the query vector for this head
                const q = s.q.subarray(h * head_dim, (h + 1) * head_dim);
                // attention scores for this head
                const att = s.att.subarray(h * cfg.block_size, (h + 1) * cfg.block_size);
                // iterate over all timesteps, including the current one
                for (let t = 0; t <= pos; t++) {
                    // get the key vector for this head and at this timestep
                    const k = s.key_cache.subarray(loff + t * dim + h * head_dim, loff + (t + 1) * dim + h * head_dim);
                    // calculate the attention score as the dot product of q and k
                    let score = 0.0;
                    for (let i = 0; i < head_dim; i++) {
                        score += q[i] * k[i];
                    }
                    score /= Math.sqrt(head_dim);
                    // save the score to the attention buffer
                    att[t] = score;
                }

                // softmax the scores to get attention weights, from 0..pos inclusively
                softmax(att, pos + 1);

                // weighted sum of the values, store back into xb
                for (let i = 0; i < head_dim; i++) {
                    let val = 0.0;
                    for (let t = 0; t <= pos; t++) {
                        val += att[t] * s.value_cache[loff + t * dim + h * head_dim + i]; // note bad locality
                    }
                    s.xb[h * head_dim + i] = val;
                }
            }

            // final matmul to get the output of the attention
            matmul(s.xb2, s.xb, w.wo.subarray(l * dim * dim, (l + 1) * dim * dim), dim, dim);

            // residual connection back into x
            accum(x, s.xb2, dim);

            // ffn rmsnorm
            rmsnorm(s.xb, x, w.rms_ffn_weight.subarray(l * dim, (l + 1) * dim), dim);

            // Now for FFN in PyTorch we have: self.w2(F.silu(self.w1(x)) * self.w3(x))
            // first calculate self.w1(x) and self.w3(x)
            matmul(s.hb, s.xb, w.w1.subarray(l * dim * hidden_dim, (l + 1) * dim * hidden_dim), dim, hidden_dim);
            matmul(s.hb2, s.xb, w.w3.subarray(l * dim * hidden_dim, (l + 1) * dim * hidden_dim), dim, hidden_dim);

            // F.silu; silu(x)=x*σ(x),where σ(x) is the logistic sigmoid
            for (let i = 0; i < hidden_dim; i++) {
                s.hb[i] = s.hb[i] * (1.0 / (1.0 + Math.exp(-s.hb[i])));
            }

            // elementwise multiply with w3(x)
            for (let i = 0; i < hidden_dim; i++) {
                s.hb[i] = s.hb[i] * s.hb2[i];
            }

            // final matmul to get the output of the ffn
            matmul(s.xb, s.hb, w.w2.subarray(l * dim * hidden_dim, (l + 1) * dim * hidden_dim), hidden_dim, dim);

            // residual connection
            accum(x, s.xb, dim);
        }

        // final rmsnorm
        rmsnorm(x, x, w.rms_final_weight, dim);

        // classifier into logits
        matmul(s.logits, x, w.wcls, cfg.n_embd, cfg.vocab_size);
    }

    // ----------------------------------------------------------------------------
    // byte pair encoding (BPE) tokenizer, encodes strings into tokens so we can prompt

    function bpe_encode(text) {
        let ids = [];
        for(let i = 0; i < text.length; i++) {
            ids.push(tokenizer_config.stoi[text[i]]);
        }
        return ids;
    }

    // ----------------------------------------------------------------------------

    function sample(probabilities, n) {
        // sample index from probabilities, they must sum to 1
        const r = Math.random();
        let cdf = 0.0;
        for (let i = 0; i < n; i++) {
            cdf += probabilities[i];
            if (r < cdf) {
                return i;
            }
        }
        return n - 1; // in case of rounding errors
    }

    function sample_topp(probabilities, n, topp) {
        // top-p sampling (or "nucleus sampling") samples from the smallest set of
        // tokens that exceed probability topp. This way we never sample tokens that
        // have very low probabilities and are less likely to go "off the rails".

        // quicksort indices in descending order of probabilities
        // values smaller than (1 - topp) / (n - 1) cannot be part of the result
        // so for efficiency we crop these out as candidates before sorting
        const cutoff = (1.0 - topp) / (n - 1);
        let n0 = 0;
        let probindex = [];
        for (let i = 0; i < n; i++) {
            if (probabilities[i] >= cutoff) {
                probindex.push({index: i, prob: probabilities[i]});
                n0++;
            }
        }
        probindex.sort((a, b) => b.prob - a.prob);

        // truncate the list where cumulative probability exceeds topp
        let cumulative_prob = 0.0;
        let last_idx = n0 - 1; // in case of rounding errors consider all elements
        for (let i = 0; i < n0; i++) {
            cumulative_prob += probindex[i].prob;
            if (cumulative_prob > topp) {
                last_idx = i;
                break; // we've exceeded topp by including last_idx
            }
        }

        // sample from the truncated list
        const r = Math.random() * cumulative_prob;
        let cdf = 0.0;
        for (let i = 0; i <= last_idx; i++) {
            cdf += probindex[i].prob;
            if (r < cdf) {
                return probindex[i].index;
            }
        }
        return probindex[last_idx].index; // in case of rounding errors
    }

    function argmax(v, n) {
        // return argmax of v in elements 0..n
        let max_i = 0;
        let max_p = v[0];
        for (let i = 1; i < n; i++) {
            if (v[i] > max_p) {
                max_i = i;
                max_p = v[i];
            }
        }
        return max_i;
    }

    async function generate() {
        if(is_generating) {
            return;
        }
        is_generating = true;
        document.querySelector('#output').value = '';
        document.querySelector('#toks').textContent = '';
        const temperature = parseFloat(document.querySelector('#temperature').value);
        let steps = parseInt(document.querySelector('#steps').value);
        let elpased = [];

        let pos = 0;
        // right now we cannot run for more than cfg.block_size steps
        if (steps <= 0 || steps > config.seq_len) { steps = config.seq_len; }
        let next = 0;
        let token = 1; // 1 = BOS token in Llama-2 sentencepiece
        let topp = parseFloat(document.querySelector('#top-p').value);
        document.querySelector('#output').value += "<s>\n"; // explicit print the initial BOS token (=1), stylistically symmetric

        const prompt = document.querySelector('#prompt').value;
        let num_prompt_tokens = 0;
        let prompt_tokens;
        if (prompt) {
            prompt_tokens = bpe_encode(prompt);
            num_prompt_tokens = prompt_tokens.length;
            document.querySelector('#output').value += prompt;
        }

        while (pos < steps) {
            const start = performance.now();
            transformer(token, pos, config, run_state, weights);

            if(pos < num_prompt_tokens) {
                // if we are still processing the input prompt, force the next prompt token
                next = prompt_tokens[pos];
            } else {
                // sample the next token
                if(temperature == 0.0) {
                    // greedy argmax sampling
                    next = argmax(run_state.logits, config.vocab_size);
                } else {
                    // apply the temperature to the logits
                    for (let q=0; q<config.vocab_size; q++) { run_state.logits[q] /= temperature; }
                    // apply softmax to the logits to get the probabilities for next token
                    softmax(run_state.logits, config.vocab_size);
                    // we now want to sample from this distribution to get the next token
                    //next = sample(run_state.logits, config.vocab_size);
                    // we sample from this distribution to get the next token
                    if (topp <= 0 || topp >= 1) {
                        // simply sample from the predicted probability distribution
                        next = sample(run_state.logits, config.vocab_size);
                    } else {
                        // top-p (nucleus) sampling, clamping the least likely tokens to zero
                        next = sample_topp(run_state.logits, config.vocab_size, topp);
                    }
                }
                await new Promise(resolve => setTimeout(resolve, 0));
                // following BOS token (1), sentencepiece decoder strips any leading whitespace (see PR #89)
                if (token == 1 && vocab[next][0] == ' ') {
                    document.querySelector('#output').value += vocab[next].slice(1);
                } else {
                    document.querySelector('#output').value += vocab[next];
                }
            }
            // advance forward
            token = next;
            pos++;
            // report achieved tok/s
            const end = performance.now();
            elpased.push(1 / (end-start)*1000);
            document.querySelector('#toks').textContent = elpased.slice(-1)[0].toFixed(4);
        }
        const avg = elpased.reduce((a, b) => a + b) / elpased.length;
        document.querySelector('#toks').textContent = avg.toFixed(4);
        is_generating = false;
    }

    async function init() {
        await load_model('test.bin');
        generate();
    }

    document.querySelector('#run').addEventListener('click', generate);
    // select another model
    document.querySelector('#model').addEventListener('change', async function() {
        await load_model(this.value + '.bin');
        generate();
    });

    init();
</script>
